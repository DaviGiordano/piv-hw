{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as spio\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the images, keypoints, and descriptors\n",
    "data_path = Path(os.getcwd()) / 'isr_wall'\n",
    "\n",
    "keypoints_fpaths = sorted((data_path / 'keypoints').glob('*.mat'),\n",
    "                     key=lambda x: int(x.stem.split('_')[1])\n",
    "                    )\n",
    "\n",
    "images_fpaths = sorted((data_path / 'images').glob('*.jpg'),\n",
    "                     key=lambda x: int(x.stem.split('_')[1])\n",
    "                    )\n",
    "\n",
    "keypoints = [spio.loadmat(fpath)['kp'] for fpath in keypoints_fpaths]\n",
    "descriptors = [spio.loadmat(fpath)['desc'] for fpath in keypoints_fpaths]\n",
    "images = [np.array(Image.open(fpath)) for fpath in images_fpaths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for keypoint matching\n",
    "def find_idx_matches(descs_img_1, descs_img_2):\n",
    "    matches_idx = []\n",
    "    for src_idx, desc in enumerate(descs_img_1):\n",
    "        desc_diffs = descs_img_2 - desc\n",
    "        norms = np.linalg.norm(desc_diffs, axis=1)\n",
    "        best_dest_idx = np.argmin(norms)\n",
    "        matches_idx.append((src_idx, best_dest_idx))\n",
    "    return matches_idx\n",
    "\n",
    "# Function for finding keypoint matches\n",
    "def find_keypoint_matches(descs_1, descs_2, keypoints_1, keypoints_2):\n",
    "    matches_idx = find_idx_matches(descs_1, descs_2)\n",
    "    matches = []\n",
    "\n",
    "    for src_idx, dest_idx in matches_idx:\n",
    "        src_kp = keypoints_1[src_idx]\n",
    "        dest_kp = keypoints_2[dest_idx]\n",
    "        matches.append([src_kp[0], src_kp[1], dest_kp[0], dest_kp[1]])\n",
    "    \n",
    "    return np.array(matches)\n",
    "\n",
    "# Homography computation\n",
    "def compute_homography(src_pts, dst_pts):\n",
    "    num_points = src_pts.shape[0]\n",
    "    A = []\n",
    "    \n",
    "    for i in range(num_points):\n",
    "        x, y = src_pts[i]\n",
    "        x_prime, y_prime = dst_pts[i]\n",
    "        A.append([-x, -y, -1, 0, 0, 0, x * x_prime, y * x_prime, x_prime])\n",
    "        A.append([0, 0, 0, -x, -y, -1, x * y_prime, y * y_prime, y_prime])\n",
    "    \n",
    "    A = np.array(A)\n",
    "    _, _, Vt = np.linalg.svd(A)\n",
    "    h = Vt[-1]\n",
    "    H = h.reshape(3, 3)\n",
    "    return H / H[-1, -1]\n",
    "\n",
    "\"\"\"\" RANSAC\n",
    "\n",
    "Given N samples \n",
    "\n",
    "1) Randomly draw n samples\n",
    "2) Estimate Model\n",
    "3) Select inliers by computing the error and apply threshold\n",
    "\n",
    "repeate 1), 2), 3) K times\n",
    "\n",
    "4) Select Model with the most inliers\n",
    "5) reestimade the model with all inliers\n",
    "\n",
    "\"\"\"\n",
    "def compute_ransac_homography(src_pts, dst_pts, threshold=5.0, K=1000, P=0.99):\n",
    "    \"\"\"Compute homography using RANSAC.\"\"\"\n",
    "    best_H = None\n",
    "    max_inliers = 0\n",
    "    n_points = len(src_pts)\n",
    "    best_inlier_src, best_inlier_dst = None, None\n",
    "    \n",
    "    for _ in range(K):\n",
    "        # 1) Randomly draw 4 samples\n",
    "        indices = np.random.choice(n_points, 4, replace=False)\n",
    "        sample_src = src_pts[indices]\n",
    "        sample_dst = dst_pts[indices]\n",
    "\n",
    "        # 2) Estimate Model\n",
    "        try:\n",
    "            H = compute_homography(sample_src, sample_dst)\n",
    "        except ValueError:\n",
    "            # Skip degenerate configurations\n",
    "            continue\n",
    "\n",
    "        # 3) Select inliers by computing the error and apply threshold\n",
    "        # Project all points\n",
    "        src_homog = np.hstack((src_pts, np.ones((n_points, 1))))  # Convert to homogeneous\n",
    "        projected_pts = (H @ src_homog.T).T\n",
    "        projected_pts /= projected_pts[:, 2:3]  # Normalize to inhomogeneous\n",
    "        distances = np.linalg.norm(projected_pts[:, :2] - dst_pts, axis=1)\n",
    "        inliers = distances < threshold\n",
    "\n",
    "        # Update best homography if more inliers are found\n",
    "        num_inliers = np.sum(inliers)\n",
    "        if num_inliers > max_inliers:\n",
    "            max_inliers = num_inliers\n",
    "            best_H = H\n",
    "            best_inlier_src = src_pts[inliers]\n",
    "            best_inlier_dst = dst_pts[inliers]\n",
    "\n",
    "    # 5) Re-estimate model with all inliers\n",
    "    if max_inliers > 0:\n",
    "        best_H = compute_homography(best_inlier_src, best_inlier_dst)\n",
    "    \n",
    "    return best_inlier_src, best_inlier_dst, best_H\n",
    "\n",
    "def compute_homographies(num_images, keypoints, descriptors):\n",
    "\n",
    "    #Match keypoints and compute homographies for each consecutive pair of images.\n",
    "    homographies = []\n",
    "\n",
    "    for i in range(num_images - 1):\n",
    "        # Find matches between keypoints\n",
    "        kp_matches = find_keypoint_matches(descriptors[i], descriptors[i+1], keypoints[i], keypoints[i+1])\n",
    "        src_pts = kp_matches[:, :2]\n",
    "        dst_pts = kp_matches[:, 2:]\n",
    "        \n",
    "        # Compute homography using RANSAC\n",
    "        _, _, H = compute_ransac_homography(src_pts, dst_pts, threshold=5.0, K=10000, P=0.99)\n",
    "\n",
    "        homographies.append(H)\n",
    "\n",
    "    return homographies\n",
    "\n",
    "#homographies = compute_homographies(len(images), keypoints, descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cumulative_homographies(num_images, keypoints, descriptors, ref_index=0):\n",
    "    \"\"\"Compute homographies between each image and a reference image.\"\"\"\n",
    "    homographies = [np.eye(3)]  # Homography from the reference image to itself is identity\n",
    "    \n",
    "    for i in range(1, num_images):\n",
    "        # Find matches between keypoints of consecutive images\n",
    "        kp_matches = find_keypoint_matches(descriptors[i-1], descriptors[i], keypoints[i-1], keypoints[i])\n",
    "        src_pts = kp_matches[:, :2]\n",
    "        dst_pts = kp_matches[:, 2:]\n",
    "        \n",
    "        # Compute homography between consecutive images using RANSAC\n",
    "        _, _, H_i_to_i_minus_1 = compute_ransac_homography(src_pts, dst_pts, threshold=5.0, K=1000, P=0.99)\n",
    "        \n",
    "        homographies.append(homographies[-1] @ np.linalg.inv(H_i_to_i_minus_1))\n",
    "    \n",
    "    return homographies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cumulative_homographies_optimized(num_images, keypoints, descriptors, ref_index=0, inlier_threshold=30):\n",
    "    \"\"\"Compute cumulative homographies with an optimization to use direct transformations when possible.\"\"\"\n",
    "    homographies = [np.eye(3)]  # Homography from the reference image to itself is identity\n",
    "\n",
    "    for i in range(1, num_images):\n",
    "        print(f\"Computing transformation for image {i + 1} ...\")\n",
    "        \n",
    "        # Find matches between current image and reference image\n",
    "        kp_matches_ref = find_keypoint_matches(descriptors[ref_index], descriptors[i], keypoints[ref_index], keypoints[i])\n",
    "        src_pts_ref = kp_matches_ref[:, :2]\n",
    "        dst_pts_ref = kp_matches_ref[:, 2:]\n",
    "        \n",
    "        # Compute homography between reference and current image using RANSAC\n",
    "        inlier_src_pts, inlier_dst_pts, H_ref_to_i = compute_ransac_homography(src_pts_ref, dst_pts_ref, threshold=5.0, K=1000, P=0.99)\n",
    "        \n",
    "        # Count the number of inliers (size of the inlier points)\n",
    "        num_inliers = inlier_src_pts.shape[0]\n",
    "        print(f\"Inliers between {ref_index} and {i + 1} is : {num_inliers}.\")\n",
    "\n",
    "        if num_inliers >= inlier_threshold:\n",
    "            print(f\"Using direct transformation.\")\n",
    "            # Use direct transformation if enough inliers are found\n",
    "            homographies.append(H_ref_to_i)\n",
    "        else:\n",
    "            # Fallback to cumulative chaining\n",
    "            print(f\"Fallback to cumulative chaining.\")\n",
    "            kp_matches = find_keypoint_matches(descriptors[i - 1], descriptors[i], keypoints[i - 1], keypoints[i])\n",
    "            src_pts = kp_matches[:, :2]\n",
    "            dst_pts = kp_matches[:, 2:]\n",
    "\n",
    "            _, _, H_i_to_i_minus_1 = compute_ransac_homography(src_pts, dst_pts, threshold=5.0, K=1000, P=0.99)\n",
    "            \n",
    "            # Cumulative homography\n",
    "            homographies.append(homographies[-1] @ np.linalg.inv(H_i_to_i_minus_1))\n",
    "\n",
    "\n",
    "        ##THIS IS JUST FOR VISUALIZATION\n",
    "\n",
    "        # Visualization of keypoints and inliers\n",
    "        print(f\"Visualizing keypoints and inliers between image 1 and image {i + 1}...\")\n",
    "\n",
    "        # Apply the homography to the points from the reference image\n",
    "        src_homog_ref = np.hstack((inlier_src_pts, np.ones((inlier_src_pts.shape[0], 1))))  # Convert to homogeneous\n",
    "        projected_pts = (H_ref_to_i @ src_homog_ref.T).T\n",
    "        projected_pts /= projected_pts[:, 2:3]  # Normalize to get (x, y) coordinates\n",
    "\n",
    "        # Plot the images side by side\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "        # Load images\n",
    "        ref_image = cv2.imread(\"isr_wall/images/img_0001.jpg\")  # Load reference image (image 1)\n",
    "        curr_image = cv2.imread(f\"isr_wall/images/img_000{i + 1}.jpg\")  # Load the current image (image i)\n",
    "\n",
    "        # Convert images to RGB for matplotlib display\n",
    "        ref_image_rgb = cv2.cvtColor(ref_image, cv2.COLOR_BGR2RGB)\n",
    "        curr_image_rgb = cv2.cvtColor(curr_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Plot the reference image with keypoints and inliers\n",
    "        ax[0].imshow(ref_image_rgb)\n",
    "        ax[0].scatter(src_pts_ref[:, 0], src_pts_ref[:, 1], color='g', s=5, label='Keypoints on Ref Image')\n",
    "        ax[0].scatter(inlier_src_pts[:, 0], inlier_src_pts[:, 1], color='r', s=5, label='Inliers on Ref Image')\n",
    "        ax[0].set_title(f\"Reference Image (Image 1)\")\n",
    "        ax[0].legend()\n",
    "\n",
    "        # Plot the current image with projected inliers\n",
    "        ax[1].imshow(curr_image_rgb)\n",
    "        ax[1].scatter(dst_pts_ref[:, 0], dst_pts_ref[:, 1], color='g', s=5, label='Keypoints on Ref Image')\n",
    "        ax[1].scatter(projected_pts[:, 0], projected_pts[:, 1], color='r', s=5, label='Inliers on Transformed Image')\n",
    "        ax[1].set_title(f\"Transformed Image {i + 1}\")\n",
    "        ax[1].legend()\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    print(f\"Finshed calculating transformations\")\n",
    "    return homographies\n",
    "\n",
    "\n",
    "cumulative_homographies = compute_cumulative_homographies_optimized(len(images), keypoints, descriptors, ref_index=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
