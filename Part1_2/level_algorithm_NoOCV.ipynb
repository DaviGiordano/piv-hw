{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import scipy.io as spio\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from utils import ImageNode\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DISTANCE_THRESHOLD_PERCENTILE = 90\n",
    "RANSAC_THRESHOLD = 5\n",
    "SCALE_FACTOR = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(os.getcwd()) / 'volley'\n",
    "\n",
    "kps_fpaths = sorted((data_path / 'input').glob('kp*.mat'),\n",
    "                     key=lambda x: int(x.stem.split('_')[1])\n",
    "                    )\n",
    "\n",
    "imgs_fpaths = sorted((data_path / 'input').glob('*.jpg'),\n",
    "                     key=lambda x: int(x.stem.split('_')[1])\n",
    "                    )\n",
    "\n",
    "ref_kps_fpath = data_path / 'reference' / 'kp_ref.mat'\n",
    "ref_img_fpath = data_path / 'reference' / 'img_ref.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load keypoints and descriptors supplied\n",
    "\n",
    "keypoints = [spio.loadmat(fpath)['kp'] for fpath in kps_fpaths]\n",
    "descriptors = [spio.loadmat(fpath)['desc'] for fpath in kps_fpaths]\n",
    "\n",
    "ref_keypoints = spio.loadmat(ref_kps_fpath)['kp']\n",
    "ref_descriptors = spio.loadmat(ref_kps_fpath)['desc']\n",
    "\n",
    "images = [np.array(Image.open(fpath)) for fpath in imgs_fpaths]\n",
    "ref_img = np.array(Image.open(ref_img_fpath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Optional: recalculate SIFT with descriptors of size 128\n",
    "\n",
    "# sift = cv2.SIFT_create()\n",
    "\n",
    "# # Extract keypoints and descriptors for each image\n",
    "# keypoints = []\n",
    "# descriptors = []\n",
    "\n",
    "# for img in tqdm(images):\n",
    "#     kps, descs = sift.detectAndCompute(img, None)\n",
    "#     keypoints_array = np.array([kp.pt for kp in kps], dtype=np.float32)\n",
    "#     descs = descs.astype(np.float32)\n",
    "#     keypoints.append(keypoints_array)\n",
    "#     descriptors.append(descs)\n",
    "\n",
    "# # Extract keypoints and descriptors for the reference image\n",
    "# kps, descs = sift.detectAndCompute(ref_img, None)\n",
    "# ref_descriptors = descs.astype(np.float32)\n",
    "# ref_keypoints = np.array([kp.pt for kp in kps], dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import resize_keypoint_and_image\n",
    "\n",
    "for i in range(len(keypoints)):\n",
    "    keypoints[i], images[i] = resize_keypoint_and_image(keypoints[i], images[i], SCALE_FACTOR)\n",
    "    \n",
    "ref_keypoints, ref_img = resize_keypoint_and_image(ref_keypoints, ref_img, SCALE_FACTOR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_nodes = [ImageNode(image, kp, desc, idx) for idx, (image, kp, desc) in enumerate(zip(images, keypoints, descriptors))]\n",
    "image_node_ref = ImageNode(ref_img, ref_keypoints, ref_descriptors, idx=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(image_nodes[0].image, cmap='gray')\n",
    "plt.scatter(image_nodes[0].keypoints[:, 0], image_nodes[0].keypoints[:, 1], c='r', s=10)\n",
    "plt.title(\"Filtered Keypoints on first Image\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(ref_img, cmap='gray')\n",
    "plt.scatter(ref_keypoints[:, 0], ref_keypoints[:, 1], c='r', s=10)\n",
    "plt.title(\"Filtered Keypoints on Reference Image\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Compute thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for keypoint matching\n",
    "def find_idx_matches(descs_img_1, descs_img_2, distance_threshold_percentile=DISTANCE_THRESHOLD_PERCENTILE):\n",
    "    matches_idx = []\n",
    "    for src_idx, desc in enumerate(descs_img_1):\n",
    "        desc_diffs = descs_img_2 - desc\n",
    "        norms = np.linalg.norm(desc_diffs, axis=1)\n",
    "        best_dest_idx = np.argmin(norms)\n",
    "        if norms[best_dest_idx] <= distance_threshold_percentile:\n",
    "            matches_idx.append((src_idx, best_dest_idx))\n",
    "    return matches_idx\n",
    "\n",
    "# Function for finding keypoint matches\n",
    "def find_keypoint_matches(descs_1, descs_2, keypoints_1, keypoints_2, distance_threshold_percentile=DISTANCE_THRESHOLD_PERCENTILE):\n",
    "    matches_idx = find_idx_matches(descs_1, descs_2, distance_threshold_percentile)\n",
    "    matches = []\n",
    "\n",
    "    for src_idx, dest_idx in matches_idx:\n",
    "        src_kp = keypoints_1[src_idx]\n",
    "        dest_kp = keypoints_2[dest_idx]\n",
    "        matches.append([src_kp[0], src_kp[1], dest_kp[0], dest_kp[1]])\n",
    "    \n",
    "    return np.array(matches)\n",
    "\n",
    "def find_matches(src_node, dst_node, distance_threshold_percentile=DISTANCE_THRESHOLD_PERCENTILE):\n",
    "    kp_matches = find_keypoint_matches(src_node.descriptors, dst_node.descriptors, src_node.keypoints, dst_node.keypoints, distance_threshold_percentile)\n",
    "    src_pts = kp_matches[:, :2]\n",
    "    dst_pts = kp_matches[:, 2:]\n",
    "\n",
    "    return src_pts, dst_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_descriptor_distance_threshold(image_nodes, distance_threshold_percentile=DISTANCE_THRESHOLD_PERCENTILE):\n",
    "    all_thresholds = []\n",
    "    \n",
    "    for i in range(len(image_nodes) - 1):\n",
    "        # Extract descriptors for the current pair of nodes\n",
    "        src_desc = image_nodes[i].descriptors\n",
    "        dst_desc = image_nodes[i + 1].descriptors\n",
    "        \n",
    "        # Perform matching\n",
    "        matches_idx = find_idx_matches(src_desc, dst_desc)\n",
    "        \n",
    "        # Compute distances for all matches\n",
    "        distances = []\n",
    "        for src_idx, dst_idx in matches_idx:\n",
    "            desc_diff = src_desc[src_idx] - dst_desc[dst_idx]\n",
    "            distances.append(np.linalg.norm(desc_diff))\n",
    "        \n",
    "        # Compute the distance threshold for the current pair\n",
    "        curr_threshold = np.percentile(distances, distance_threshold_percentile)\n",
    "        all_thresholds.append(curr_threshold)\n",
    "    \n",
    "    # Maximum threshold across all image pairs\n",
    "    descriptor_distance_threshold = max(all_thresholds)\n",
    "    return descriptor_distance_threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Homography computation\n",
    "def compute_homography(src_pts, dst_pts):\n",
    "    num_points = src_pts.shape[0]\n",
    "    A = []\n",
    "    \n",
    "    for i in range(num_points):\n",
    "        x, y = src_pts[i]\n",
    "        x_prime, y_prime = dst_pts[i]\n",
    "        A.append([-x, -y, -1, 0, 0, 0, x * x_prime, y * x_prime, x_prime])\n",
    "        A.append([0, 0, 0, -x, -y, -1, x * y_prime, y * y_prime, y_prime])\n",
    "    \n",
    "    A = np.array(A)\n",
    "    _, _, Vt = np.linalg.svd(A)\n",
    "    h = Vt[-1]\n",
    "    H = h.reshape(3, 3)\n",
    "    return H / H[-1, -1]\n",
    "\n",
    "\"\"\"\" RANSAC\n",
    "\n",
    "Given N samples \n",
    "\n",
    "1) Randomly draw n samples\n",
    "2) Estimate Model\n",
    "3) Select inliers by computing the error and apply threshold\n",
    "\n",
    "repeate 1), 2), 3) K times\n",
    "\n",
    "4) Select Model with the most inliers\n",
    "5) reestimade the model with all inliers\n",
    "\n",
    "\"\"\"\n",
    "def compute_ransac_homography(src_pts, dst_pts, threshold=RANSAC_THRESHOLD, K=1000):\n",
    "    \"\"\"Compute homography using RANSAC.\"\"\"\n",
    "    best_H = None\n",
    "    max_inliers = 0\n",
    "    n_points = len(src_pts)\n",
    "    best_inlier_src, best_inlier_dst = None, None\n",
    "    \n",
    "    for _ in range(K):\n",
    "        # 1) Randomly draw 4 samples\n",
    "        indices = np.random.choice(n_points, 4, replace=False)\n",
    "        sample_src = src_pts[indices]\n",
    "        sample_dst = dst_pts[indices]\n",
    "\n",
    "        # 2) Estimate Model\n",
    "        try:\n",
    "            H = compute_homography(sample_src, sample_dst)\n",
    "        except ValueError:\n",
    "            # Skip degenerate configurations\n",
    "            continue\n",
    "\n",
    "        # 3) Select inliers by computing the error and apply threshold\n",
    "        # Project all points\n",
    "        src_homog = np.hstack((src_pts, np.ones((n_points, 1))))  # Convert to homogeneous\n",
    "        projected_pts = (H @ src_homog.T).T\n",
    "        projected_pts /= projected_pts[:, 2:3]  # Normalize to inhomogeneous\n",
    "        distances = np.linalg.norm(projected_pts[:, :2] - dst_pts, axis=1)\n",
    "        inliers = distances < threshold\n",
    "\n",
    "        # Update best homography if more inliers are found\n",
    "        num_inliers = np.sum(inliers)\n",
    "        if num_inliers > max_inliers:\n",
    "            max_inliers = num_inliers\n",
    "            best_H = H\n",
    "            best_inlier_src = src_pts[inliers]\n",
    "            best_inlier_dst = dst_pts[inliers]\n",
    "\n",
    "    # 5) Re-estimate model with all inliers\n",
    "    if max_inliers > 0:\n",
    "        best_H = compute_homography(best_inlier_src, best_inlier_dst)\n",
    "    \n",
    "    return best_inlier_src, best_inlier_dst, best_H\n",
    "\n",
    "def compute_min_inliers_threshold(image_nodes, max_desc_dist):\n",
    "    inliers_per_pair = []\n",
    "\n",
    "    for i in range(len(image_nodes) - 1):\n",
    "        src_pts, dst_pts = find_matches(image_nodes[i], image_nodes[i+1], max_desc_dist)\n",
    "        inliers, _, H = compute_ransac_homography(src_pts, dst_pts, threshold=RANSAC_THRESHOLD, K=10000)\n",
    "        inliers_per_pair.append(len(inliers))\n",
    "\n",
    "    min_inliers = min(inliers_per_pair)\n",
    "    return min_inliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_min_inliers_threshold(image_nodes, max_desc_dist):\n",
    "    inliers_per_pair = []\n",
    "\n",
    "    for i in range(len(image_nodes) - 1):\n",
    "        src_pts, dst_pts = find_matches(image_nodes[i], image_nodes[i+1], max_desc_dist)\n",
    "        inliers, _, H = compute_ransac_homography(src_pts, dst_pts, threshold=RANSAC_THRESHOLD, K=19)\n",
    "        inliers_per_pair.append(len(inliers))\n",
    "\n",
    "    min_inliers = min(inliers_per_pair)\n",
    "    return min_inliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_desc_dist = max_descriptor_distance_threshold(image_nodes, DISTANCE_THRESHOLD_PERCENTILE)\n",
    "print('The maximum descriptor distance is:', round(max_desc_dist, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_inliers_threshold = compute_min_inliers_threshold(image_nodes, max_desc_dist)\n",
    "print('The minimum number of inliers is:', min_inliers_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Compute homographies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_valid_homography(src_node, dst_node, min_inliers_threshold, max_desc_dist):\n",
    "    src_pts, dst_pts = find_matches(src_node, dst_node, max_desc_dist)\n",
    "    # print(f'Number of matches: {len(src_pts)}')\n",
    "    inliers, _, H = compute_ransac_homography(src_pts, dst_pts, threshold=RANSAC_THRESHOLD, K=10000)\n",
    "    num_inliers = len(inliers)\n",
    "    is_H_valid = 1 if num_inliers >= min_inliers_threshold else 0\n",
    "    return H, is_H_valid, num_inliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_direct_homographies(image_nodes, image_node_ref, min_inliers_threshold, max_desc_dist):\n",
    "    valid_homographies = {1: []}\n",
    "\n",
    "    for i in tqdm(range(len(image_nodes))):\n",
    "        H, is_H_valid, num_inliers = find_valid_homography(image_nodes[i], image_node_ref, min_inliers_threshold, max_desc_dist)\n",
    "        \n",
    "        if is_H_valid:\n",
    "            image_nodes[i].homography = H\n",
    "            image_nodes[i].footprint.append('ref')\n",
    "            valid_homographies[1].append(i)\n",
    "    return valid_homographies\n",
    "\n",
    "valid_homographies = find_direct_homographies(image_nodes, image_node_ref, min_inliers_threshold, max_desc_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "def find_remaining_homographies(image_nodes, valid_homographies, min_inliers_threshold, max_desc_dist):\n",
    "    level = 1\n",
    "    while level in valid_homographies:\n",
    "        best_idxs = valid_homographies[level]\n",
    "        for node in tqdm(image_nodes):\n",
    "            if node.idx in list(chain.from_iterable(valid_homographies.values())):\n",
    "                continue\n",
    "\n",
    "            nearest_idx = min(best_idxs, key=lambda x: abs(x - node.idx))\n",
    "            H, is_H_valid, num_inliers = find_valid_homography(node, image_nodes[nearest_idx], min_inliers_threshold, max_desc_dist)\n",
    "\n",
    "            if is_H_valid:\n",
    "                node.homography = np.dot(image_nodes[nearest_idx].homography, H)\n",
    "                valid_homographies.setdefault(level + 1, []).append(node.idx)\n",
    "                node.footprint.extend(image_nodes[nearest_idx].footprint)\n",
    "        level += 1\n",
    "\n",
    "find_remaining_homographies(image_nodes, valid_homographies, min_inliers_threshold, max_desc_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Visualize results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Visualize matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot import draw_matches_points\n",
    "\n",
    "\n",
    "def show_keypoints_matches(node1, node2, max_desc_dist, num_matches):\n",
    "    \"\"\"\n",
    "    Show the keypoints matches between two image nodes.\n",
    "\n",
    "    Args:\n",
    "        node1 (ImageNode): The first image node.\n",
    "        node2 (ImageNode): The second image node.\n",
    "    \"\"\"\n",
    "    src_pts, dst_pts = find_matches(node1, node2, max_desc_dist)\n",
    "\n",
    "    img_matches = draw_matches_points(node1.image, node2.image, src_pts, dst_pts, num_matches)\n",
    "\n",
    "    # Display the matches\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.imshow(img_matches)\n",
    "    plt.title(f\"Keypoints Matches between Image {node1.idx} and Image {node2.idx}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counter = 0\n",
    "# num_plots = 1000\n",
    "# for node in image_nodes:\n",
    "#     if counter == num_plots:\n",
    "#         break\n",
    "#     if node.footprint == ['ref']:\n",
    "#         show_keypoints_matches(node, image_node_ref, max_desc_dist, num_matches=50)\n",
    "#         counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Visualize inlier matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_inlier_matches(node1, node2, max_desc_dist=None, ransac_threshold=RANSAC_THRESHOLD, max_points=None):\n",
    "    \"\"\"\n",
    "    Finds matches between two image nodes, computes a homography, and\n",
    "    visualizes only the inlier matches.\n",
    "\n",
    "    Args:\n",
    "        node1 (ImageNode): The first image node (has .image, .keypoints, .descriptors).\n",
    "        node2 (ImageNode): The second image node.\n",
    "        max_desc_dist (float, optional): Maximum descriptor distance to keep a match.\n",
    "        ransac_threshold (float): Threshold for RANSAC homography.\n",
    "        max_points (int or None): If int, draw up to this many inlier points.\n",
    "                                  If None, draw all inliers.\n",
    "    \"\"\"\n",
    "    # 1) Find initial descriptor matches + their points\n",
    "    src_pts, dst_pts = find_matches(node1, node2, max_desc_dist)\n",
    "\n",
    "    # 2) Compute homography and get RANSAC's inlier mask\n",
    "    \"\"\" H, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, ransac_threshold)\n",
    "    if mask is None:\n",
    "        print(\"No homography could be computed.\")\n",
    "        return\n",
    "\n",
    "    # 3) Filter only inlier points\n",
    "    inlier_indices = np.where(mask.flatten() == 1)[0]\n",
    "    inlier_src_pts = src_pts[inlier_indices]\n",
    "    inlier_dst_pts = dst_pts[inlier_indices] \"\"\"\n",
    "    inlier_src_pts, inlier_dst_pts, H = compute_ransac_homography(src_pts, dst_pts, threshold=ransac_threshold, K=10000)\n",
    "\n",
    "    # 4) Draw the inlier matches in a side-by-side image\n",
    "    out_image = draw_matches_points(\n",
    "        node1.image, node2.image,\n",
    "        inlier_src_pts, inlier_dst_pts,\n",
    "        max_points=max_points\n",
    "    )\n",
    "\n",
    "    # 5) Show the result\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.imshow(out_image)\n",
    "    plt.title(f\"Inlier Matches between Node {node1.idx} and Node {node2.idx}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counter = 0\n",
    "# num_plots = 1000\n",
    "# for node in image_nodes:\n",
    "#     if counter == num_plots:\n",
    "#         break\n",
    "#     if node.footprint == ['ref']:\n",
    "#         visualize_inlier_matches(node, image_node_ref, max_desc_dist, RANSAC_THRESHOLD, 50)\n",
    "#         counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.3 Visualize path inlier matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import print_footprints\n",
    "\n",
    "print_footprints(image_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_node = image_nodes[2]\n",
    "num_matches = 50\n",
    "for idx in range(len(starting_node.footprint)-1):\n",
    "    if starting_node.footprint[idx+1] == 'ref':\n",
    "        show_inlier_matches(image_nodes[starting_node.footprint[idx]], image_node_ref, max_desc_dist, RANSAC_THRESHOLD, num_matches)\n",
    "    if idx + 1 < len(starting_node.footprint) and starting_node.footprint[idx+1] != 'ref':\n",
    "        show_inlier_matches(image_nodes[starting_node.footprint[idx]], image_nodes[starting_node.footprint[idx + 1]], max_desc_dist, RANSAC_THRESHOLD, num_matches)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot import create_canvas_with_images\n",
    "\n",
    "# Example usage:\n",
    "final_canvas = create_canvas_with_images(ref_img, image_nodes)\n",
    "\n",
    "# Display the final canvas\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.imshow(final_canvas)\n",
    "plt.title(\"Final Canvas with All Images in Reference Frame\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sandbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
